name: PR Feedback & Analytics

on:
  pull_request:
    types: [opened, synchronize, reopened, ready_for_review]
  pull_request_review:
    types: [submitted]
  issue_comment:
    types: [created]

permissions:
  contents: read
  pull-requests: write
  issues: write
  checks: write

jobs:
  # PR analysis and feedback
  pr-analysis:
    name: PR Analysis
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    timeout-minutes: 15

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Install Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: pr-analysis-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Analyze PR changes
      id: analysis
      run: |
        python3 << 'EOF'
        import os
        import subprocess
        import json
        from pathlib import Path

        def get_pr_stats():
            # Get changed files
            result = subprocess.run(['git', 'diff', '--name-only', 'origin/main...HEAD'],
                                  capture_output=True, text=True)
            changed_files = result.stdout.strip().split('\n') if result.stdout.strip() else []

            # Categorize changes
            rust_files = [f for f in changed_files if f.endswith('.rs')]
            test_files = [f for f in changed_files if 'test' in f or f.startswith('tests/')]
            docs_files = [f for f in changed_files if f.endswith('.md') or 'doc' in f]
            config_files = [f for f in changed_files if f.endswith(('.toml', '.yml', '.yaml', '.json'))]
            workflow_files = [f for f in changed_files if f.startswith('.github/')]

            # Get diff stats
            result = subprocess.run(['git', 'diff', '--stat', 'origin/main...HEAD'],
                                  capture_output=True, text=True)
            diff_stats = result.stdout.strip()

            # Count lines changed
            result = subprocess.run(['git', 'diff', '--numstat', 'origin/main...HEAD'],
                                  capture_output=True, text=True)
            lines = result.stdout.strip().split('\n') if result.stdout.strip() else []

            total_additions = 0
            total_deletions = 0
            for line in lines:
                if line:
                    parts = line.split('\t')
                    if len(parts) >= 2 and parts[0].isdigit() and parts[1].isdigit():
                        total_additions += int(parts[0])
                        total_deletions += int(parts[1])

            return {
                'total_files': len(changed_files),
                'rust_files': len(rust_files),
                'test_files': len(test_files),
                'docs_files': len(docs_files),
                'config_files': len(config_files),
                'workflow_files': len(workflow_files),
                'total_additions': total_additions,
                'total_deletions': total_deletions,
                'diff_stats': diff_stats,
                'changed_files': changed_files[:20]  # Limit for output
            }

        def analyze_pr_complexity():
            # Simple complexity heuristics
            stats = get_pr_stats()

            complexity_score = 0
            complexity_factors = []

            # File count factor
            if stats['total_files'] > 20:
                complexity_score += 3
                complexity_factors.append(f"High file count: {stats['total_files']} files")
            elif stats['total_files'] > 10:
                complexity_score += 2
                complexity_factors.append(f"Medium file count: {stats['total_files']} files")

            # Lines changed factor
            total_changes = stats['total_additions'] + stats['total_deletions']
            if total_changes > 1000:
                complexity_score += 3
                complexity_factors.append(f"Large changeset: {total_changes} lines")
            elif total_changes > 500:
                complexity_score += 2
                complexity_factors.append(f"Medium changeset: {total_changes} lines")

            # Code vs test ratio
            if stats['rust_files'] > 0 and stats['test_files'] == 0:
                complexity_score += 2
                complexity_factors.append("No test files modified")

            # Workflow changes
            if stats['workflow_files'] > 0:
                complexity_score += 1
                complexity_factors.append("Workflow files modified")

            if complexity_score >= 6:
                complexity_level = "High"
            elif complexity_score >= 4:
                complexity_level = "Medium"
            elif complexity_score >= 2:
                complexity_level = "Low-Medium"
            else:
                complexity_level = "Low"

            return {
                'complexity_score': complexity_score,
                'complexity_level': complexity_level,
                'complexity_factors': complexity_factors
            }

        # Generate analysis
        stats = get_pr_stats()
        complexity = analyze_pr_complexity()

        analysis = {
            'stats': stats,
            'complexity': complexity
        }

        with open('pr_analysis.json', 'w') as f:
            json.dump(analysis, f, indent=2)

        print(f"Total files changed: {stats['total_files']}")
        print(f"Rust files: {stats['rust_files']}")
        print(f"Test files: {stats['test_files']}")
        print(f"Complexity: {complexity['complexity_level']}")
        EOF

    - name: Check for breaking changes
      id: breaking-changes
      run: |
        # Simple heuristic for breaking changes
        BREAKING_PATTERNS="pub fn|pub struct|pub enum|pub trait|pub const|pub static"

        if git diff origin/main...HEAD -- 'src/**/*.rs' | grep -E "^-.*($BREAKING_PATTERNS)" > /dev/null; then
          echo "potential-breaking=true" >> $GITHUB_OUTPUT
          echo "⚠️ Potential breaking changes detected"
        else
          echo "potential-breaking=false" >> $GITHUB_OUTPUT
        fi

    - name: Generate PR feedback
      id: feedback
      run: |
        python3 << 'EOF'
        import json
        import os

        # Load analysis
        with open('pr_analysis.json', 'r') as f:
            analysis = json.load(f)

        stats = analysis['stats']
        complexity = analysis['complexity']

        # Generate feedback message
        feedback = []
        feedback.append("## 🔍 PR Analysis Report")
        feedback.append("")

        # Stats table
        feedback.append("### 📊 Change Statistics")
        feedback.append("| Metric | Value |")
        feedback.append("|--------|-------|")
        feedback.append(f"| Files Changed | {stats['total_files']} |")
        feedback.append(f"| Rust Files | {stats['rust_files']} |")
        feedback.append(f"| Test Files | {stats['test_files']} |")
        feedback.append(f"| Documentation | {stats['docs_files']} |")
        feedback.append(f"| Lines Added | +{stats['total_additions']} |")
        feedback.append(f"| Lines Removed | -{stats['total_deletions']} |")
        feedback.append("")

        # Complexity analysis
        feedback.append("### 🧮 Complexity Analysis")
        feedback.append(f"**Complexity Level:** {complexity['complexity_level']}")

        if complexity['complexity_factors']:
            feedback.append("\n**Contributing Factors:**")
            for factor in complexity['complexity_factors']:
                feedback.append(f"- {factor}")
        feedback.append("")

        # Breaking changes warning
        potential_breaking = os.getenv('POTENTIAL_BREAKING', 'false')
        if potential_breaking == 'true':
            feedback.append("### ⚠️ Potential Breaking Changes")
            feedback.append("This PR may contain breaking changes to the public API. Please:")
            feedback.append("- Verify backward compatibility")
            feedback.append("- Update version number appropriately")
            feedback.append("- Document breaking changes in changelog")
            feedback.append("")

        # Recommendations
        feedback.append("### 💡 Recommendations")

        if stats['rust_files'] > 0 and stats['test_files'] == 0:
            feedback.append("- ⚠️ Consider adding tests for the Rust code changes")

        if stats['total_files'] > 15:
            feedback.append("- 💭 Large PR - consider splitting into smaller, focused changes")

        if stats['docs_files'] == 0 and stats['rust_files'] > 3:
            feedback.append("- 📝 Consider updating documentation for significant code changes")

        if complexity['complexity_level'] in ['High', 'Medium']:
            feedback.append("- 👀 Complex PR - extra review attention recommended")
            feedback.append("- 🧪 Consider additional testing")

        # General recommendations
        feedback.append("- ✅ Ensure all CI checks pass")
        feedback.append("- 🔍 Self-review the changes before requesting review")
        feedback.append("- 📝 Update changelog if this is a user-facing change")
        feedback.append("")

        feedback.append("---")
        feedback.append("*This analysis is automated. Use your judgment for the final decisions.*")

        feedback_text = '\n'.join(feedback)

        # Save for posting
        with open('pr_feedback.md', 'w') as f:
            f.write(feedback_text)

        print("PR feedback generated")
        EOF
        env:
          POTENTIAL_BREAKING: ${{ steps.breaking-changes.outputs.potential-breaking }}

    - name: Post PR feedback
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');
          const feedback = fs.readFileSync('pr_feedback.md', 'utf8');

          // Check if we already posted feedback
          const comments = await github.rest.issues.listComments({
            owner: context.repo.owner,
            repo: context.repo.repo,
            issue_number: context.issue.number
          });

          const botComments = comments.data.filter(comment =>
            comment.user.login === 'github-actions[bot]' &&
            comment.body.includes('🔍 PR Analysis Report')
          );

          if (botComments.length > 0) {
            // Update existing comment
            await github.rest.issues.updateComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              comment_id: botComments[0].id,
              body: feedback
            });
          } else {
            // Create new comment
            await github.rest.issues.createComment({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              body: feedback
            });
          }

    - name: Upload analysis results
      uses: actions/upload-artifact@v4
      with:
        name: pr-analysis-${{ github.event.number }}
        path: |
          pr_analysis.json
          pr_feedback.md
        retention-days: 30

  # Automated code suggestions
  code-suggestions:
    name: Code Suggestions
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    timeout-minutes: 20

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Install Rust toolchain
      uses: dtolnay/rust-toolchain@stable
      with:
        components: clippy, rustfmt

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: suggestions-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y pkg-config libssl-dev

    - name: Run Clippy with suggestions
      run: |
        mkdir -p suggestions

        # Run clippy on changed files only
        git diff --name-only origin/main...HEAD -- '*.rs' | while read file; do
          if [ -f "$file" ]; then
            echo "Analyzing $file..."
            cargo clippy --message-format=json --all-features -- \
              -W clippy::nursery \
              -W clippy::pedantic \
              > "suggestions/$(basename "$file" .rs).json" 2>&1 || true
          fi
        done

    - name: Format suggestions
      run: |
        python3 << 'EOF'
        import json
        import os
        from pathlib import Path

        suggestions = []
        suggestions_dir = Path('suggestions')

        if suggestions_dir.exists():
            for json_file in suggestions_dir.glob('*.json'):
                try:
                    with open(json_file, 'r') as f:
                        content = f.read()
                        # Parse each line as separate JSON (clippy output format)
                        for line in content.split('\n'):
                            if line.strip():
                                try:
                                    data = json.loads(line)
                                    if data.get('message', {}).get('level') in ['warning', 'error']:
                                        suggestions.append(data)
                                except json.JSONDecodeError:
                                    continue
                except Exception as e:
                    print(f"Error processing {json_file}: {e}")

        # Format suggestions for GitHub
        if suggestions:
            with open('code_suggestions.md', 'w') as f:
                f.write("## 💡 Code Suggestions\n\n")
                f.write("Here are some automated suggestions to improve your code:\n\n")

                for i, suggestion in enumerate(suggestions[:10], 1):  # Limit to 10
                    message = suggestion.get('message', {})
                    spans = message.get('spans', [])

                    if spans:
                        span = spans[0]
                        file_name = span.get('file_name', 'unknown')
                        line_start = span.get('line_start', 0)
                        suggestion_text = message.get('message', 'No description')

                        f.write(f"### {i}. {file_name}:{line_start}\n")
                        f.write(f"**Issue:** {suggestion_text}\n\n")

                        if span.get('suggested_replacement'):
                            f.write(f"**Suggested fix:**\n")
                            f.write(f"```rust\n{span['suggested_replacement']}\n```\n\n")

                f.write("---\n")
                f.write("*These are automated suggestions. Review them carefully before applying.*\n")
        else:
            with open('code_suggestions.md', 'w') as f:
                f.write("## ✅ Code Quality\n\n")
                f.write("Great job! No automated suggestions found.\n")
        EOF

    - name: Post code suggestions
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          if (fs.existsSync('code_suggestions.md')) {
            const suggestions = fs.readFileSync('code_suggestions.md', 'utf8');

            // Check for existing suggestions comment
            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const suggestionComments = comments.data.filter(comment =>
              comment.user.login === 'github-actions[bot]' &&
              comment.body.includes('💡 Code Suggestions')
            );

            if (suggestionComments.length > 0) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: suggestionComments[0].id,
                body: suggestions
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: suggestions
              });
            }
          }

  # Automatic labeling
  auto-labeling:
    name: Automatic Labeling
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    timeout-minutes: 5

    steps:
    - name: Checkout code
      uses: actions/checkout@v4
      with:
        fetch-depth: 0

    - name: Analyze changes and apply labels
      uses: actions/github-script@v7
      with:
        script: |
          const { data: files } = await github.rest.pulls.listFiles({
            owner: context.repo.owner,
            repo: context.repo.repo,
            pull_number: context.issue.number
          });

          const labels = new Set();

          // Analyze file changes
          for (const file of files) {
            const filename = file.filename;

            if (filename.endsWith('.rs')) {
              labels.add('rust');

              if (filename.includes('test') || filename.startsWith('tests/')) {
                labels.add('testing');
              }

              if (filename.includes('src/api/') || filename.includes('api')) {
                labels.add('api');
              }

              if (filename.includes('cli/') || filename.includes('command')) {
                labels.add('cli');
              }

              if (filename.includes('backend') || filename.includes('inference')) {
                labels.add('backend');
              }
            }

            if (filename.endsWith('.md') || filename.includes('doc')) {
              labels.add('documentation');
            }

            if (filename.includes('.github/workflows/') || filename.includes('ci')) {
              labels.add('ci/cd');
            }

            if (filename.includes('Dockerfile') || filename.includes('docker')) {
              labels.add('docker');
            }

            if (filename.includes('Cargo.toml') || filename.includes('dependencies')) {
              labels.add('dependencies');
            }
          }

          // Size-based labels
          const additions = files.reduce((sum, file) => sum + file.additions, 0);
          const deletions = files.reduce((sum, file) => sum + file.deletions, 0);
          const totalChanges = additions + deletions;

          if (totalChanges > 1000) {
            labels.add('size/XL');
          } else if (totalChanges > 500) {
            labels.add('size/L');
          } else if (totalChanges > 100) {
            labels.add('size/M');
          } else if (totalChanges > 10) {
            labels.add('size/S');
          } else {
            labels.add('size/XS');
          }

          // Apply labels
          if (labels.size > 0) {
            await github.rest.issues.addLabels({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number,
              labels: Array.from(labels)
            });
          }

  # Performance impact assessment
  performance-impact:
    name: Performance Impact
    runs-on: ubuntu-latest
    if: github.event_name == 'pull_request'
    timeout-minutes: 15

    steps:
    - name: Checkout PR branch
      uses: actions/checkout@v4

    - name: Install Rust toolchain
      uses: dtolnay/rust-toolchain@stable

    - name: Cache dependencies
      uses: actions/cache@v4
      with:
        path: |
          ~/.cargo/registry
          ~/.cargo/git
          target
        key: perf-impact-${{ runner.os }}-cargo-${{ hashFiles('**/Cargo.lock') }}

    - name: Install system dependencies
      run: |
        sudo apt-get update
        sudo apt-get install -y pkg-config libssl-dev

    - name: Build and quick benchmark
      run: |
        cargo build --release

        # Quick performance check
        time cargo run --release -- --version > perf_pr.txt 2>&1

        # Binary size check
        ls -la target/release/inferno >> perf_pr.txt

    - name: Checkout main branch
      run: |
        git fetch origin main
        git checkout origin/main

    - name: Build main branch
      run: |
        cargo build --release

        # Quick performance check
        time cargo run --release -- --version > perf_main.txt 2>&1

        # Binary size check
        ls -la target/release/inferno >> perf_main.txt

    - name: Compare performance
      run: |
        python3 << 'EOF'
        import re
        import os

        def extract_metrics(filename):
            with open(filename, 'r') as f:
                content = f.read()

            # Extract binary size
            size_match = re.search(r'-rwxr-xr-x.*?(\d+).*?inferno', content)
            size = int(size_match.group(1)) if size_match else 0

            return {'binary_size': size}

        if os.path.exists('perf_main.txt') and os.path.exists('perf_pr.txt'):
            main_metrics = extract_metrics('perf_main.txt')
            pr_metrics = extract_metrics('perf_pr.txt')

            size_diff = pr_metrics['binary_size'] - main_metrics['binary_size']
            size_diff_pct = (size_diff / main_metrics['binary_size'] * 100) if main_metrics['binary_size'] > 0 else 0

            with open('performance_impact.md', 'w') as f:
                f.write("## ⚡ Performance Impact Assessment\n\n")
                f.write("| Metric | Main Branch | PR Branch | Difference |\n")
                f.write("|--------|-------------|-----------|------------|\n")
                f.write(f"| Binary Size | {main_metrics['binary_size']:,} bytes | {pr_metrics['binary_size']:,} bytes | {size_diff:+,} bytes ({size_diff_pct:+.1f}%) |\n")
                f.write("\n")

                if abs(size_diff_pct) > 5:
                    f.write("⚠️ **Significant binary size change detected!**\n\n")
                elif size_diff_pct > 0:
                    f.write("📈 Binary size increased slightly.\n\n")
                elif size_diff_pct < 0:
                    f.write("📉 Binary size decreased - good optimization!\n\n")
                else:
                    f.write("✅ No significant size change.\n\n")

                f.write("*This is a quick assessment. Full performance testing runs in CI.*\n")
        EOF

    - name: Post performance impact
      uses: actions/github-script@v7
      with:
        script: |
          const fs = require('fs');

          if (fs.existsSync('performance_impact.md')) {
            const impact = fs.readFileSync('performance_impact.md', 'utf8');

            const comments = await github.rest.issues.listComments({
              owner: context.repo.owner,
              repo: context.repo.repo,
              issue_number: context.issue.number
            });

            const perfComments = comments.data.filter(comment =>
              comment.user.login === 'github-actions[bot]' &&
              comment.body.includes('⚡ Performance Impact Assessment')
            );

            if (perfComments.length > 0) {
              await github.rest.issues.updateComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                comment_id: perfComments[0].id,
                body: impact
              });
            } else {
              await github.rest.issues.createComment({
                owner: context.repo.owner,
                repo: context.repo.repo,
                issue_number: context.issue.number,
                body: impact
              });
            }
          }