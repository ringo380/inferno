// Simple test to verify our conversion implementation
use byteorder::{LittleEndian, WriteBytesExt};
use half::f16;
use std::collections::HashMap;
use tempfile::tempdir;

fn main() -> Result<(), Box<dyn std::error::Error>> {
    println!("Testing basic conversion functionality...");

    // Test 1: F32 to F16 conversion
    println!("1. Testing F32 to F16 conversion");
    let f32_values = vec![1.0f32, 2.5, -3.14, 0.0];
    let mut f32_bytes = Vec::new();
    for val in &f32_values {
        f32_bytes.write_f32::<LittleEndian>(*val)?;
    }

    let mut f16_bytes = Vec::new();
    for chunk in f32_bytes.chunks_exact(4) {
        let f32_val = f32::from_le_bytes([chunk[0], chunk[1], chunk[2], chunk[3]]);
        let f16_val = f16::from_f32(f32_val);
        f16_bytes.extend_from_slice(&f16_val.to_le_bytes());
    }

    println!("  Original: {:?}", f32_values);
    println!("  F32 bytes: {} bytes", f32_bytes.len());
    println!("  F16 bytes: {} bytes", f16_bytes.len());
    println!(
        "  Compression ratio: {:.2}x",
        f32_bytes.len() as f32 / f16_bytes.len() as f32
    );

    // Test 2: SafeTensors serialization
    println!("\n2. Testing SafeTensors functionality");
    let mut tensors = HashMap::new();
    let data = vec![1.0f32, 2.0, 3.0, 4.0, 5.0, 6.0];
    let bytes = data
        .iter()
        .flat_map(|f| f.to_le_bytes())
        .collect::<Vec<u8>>();

    tensors.insert(
        "test_tensor".to_string(),
        (safetensors::Dtype::F32, vec![2, 3], bytes),
    );
    let serialized = safetensors::serialize(&tensors, &None)?;
    println!("  Serialized SafeTensors size: {} bytes", serialized.len());

    // Deserialize and verify
    let deserialized = safetensors::SafeTensors::deserialize(&serialized)?;
    for (name, tensor_view) in deserialized.tensors() {
        println!(
            "  Tensor '{}': shape={:?}, dtype={:?}, size={} bytes",
            name,
            tensor_view.shape(),
            tensor_view.dtype(),
            tensor_view.data().len()
        );
    }

    // Test 3: Basic GGUF structure creation
    println!("\n3. Testing GGUF structure creation");
    let temp_dir = tempdir()?;
    let gguf_path = temp_dir.path().join("test.gguf");

    let mut gguf_data = Vec::new();
    // GGUF magic
    gguf_data.extend_from_slice(b"GGUF");
    // Version
    gguf_data.write_u32::<LittleEndian>(3)?;
    // Tensor count
    gguf_data.write_u64::<LittleEndian>(1)?;
    // Metadata count
    gguf_data.write_u64::<LittleEndian>(0)?;

    // Tensor info: name="test", 2D [2,3], F32, offset=0
    gguf_data.write_u64::<LittleEndian>(4)?; // name length
    gguf_data.extend_from_slice(b"test");
    gguf_data.write_u32::<LittleEndian>(2)?; // dimensions
    gguf_data.write_u64::<LittleEndian>(2)?; // dim 1
    gguf_data.write_u64::<LittleEndian>(3)?; // dim 2
    gguf_data.write_u32::<LittleEndian>(0)?; // F32 type
    gguf_data.write_u64::<LittleEndian>(0)?; // offset

    // Align to 32-byte boundary
    let aligned_size = (gguf_data.len() + 31) & !31;
    gguf_data.resize(aligned_size, 0);

    // Add tensor data (2*3=6 F32 values)
    for i in 0..6 {
        gguf_data.write_f32::<LittleEndian>(i as f32 + 1.0)?;
    }

    std::fs::write(&gguf_path, &gguf_data)?;
    println!("  Created GGUF file: {} bytes", gguf_data.len());

    // Verify GGUF magic
    let read_data = std::fs::read(&gguf_path)?;
    if &read_data[0..4] == b"GGUF" {
        println!("  ‚úÖ GGUF magic verified");
    } else {
        println!("  ‚ùå GGUF magic invalid");
    }

    println!("\nüéâ All basic conversion tests passed!");
    println!("‚úÖ F32 to F16 quantization works");
    println!("‚úÖ SafeTensors serialization/deserialization works");
    println!("‚úÖ Basic GGUF file creation works");
    println!("‚úÖ Real model format conversion implementation is functional!");

    Ok(())
}
