[package]
name = "inferno-ai"
version = "0.6.1"
edition = "2021"
authors = ["Inferno Developers"]
description = "Enterprise AI/ML model runner with automatic updates, real-time monitoring, and multi-interface support"
readme = "README.md"
homepage = "https://github.com/ringo380/inferno"
repository = "https://github.com/ringo380/inferno"
license = "MIT"
keywords = ["ai", "ml", "gguf", "onnx", "inference"]
categories = ["command-line-utilities", "science"]
exclude = [
    "/.github/",
    "/target/",
    "/scripts/",
    "*.log"
]

[[bin]]
name = "inferno"
path = "src/main.rs"

[[bin]]
name = "generate_icons"
path = "src/bin/generate_icons.rs"

# REMOVED: Deprecated Tauri v1 binary (inferno_app)
# Tauri v2 desktop app is now in dashboard/src-tauri/
# See: dashboard/src-tauri/src/main.rs for the new implementation

# Universal binary configuration moved to .cargo/config.toml

[dependencies]
# CLI and argument parsing
clap = { version = "4.4", features = ["derive", "env"] }

# Configuration
serde = { version = "1.0", features = ["derive"] }
toml = "0.8"
figment = { version = "0.10", features = ["toml", "env"] }

# Async runtime
tokio = { version = "1.0", features = ["full"] }
futures = "0.3"

# TUI
ratatui = "0.24"
crossterm = "0.27"

# Logging and tracing
tracing = "0.1"
tracing-subscriber = { version = "0.3", features = ["env-filter", "json"] }
tracing-appender = "0.2"

# Error handling
anyhow = "1.0"
thiserror = "1.0"

# File I/O and serialization
serde_json = "1.0"

# Image processing
image = { version = "0.24", features = ["png", "jpeg"] }

# Audio processing
hound = "3.5"

# ML backend support
llama-cpp-2 = { version = "0.1.67", optional = true }  # for GGUF support
ort = { version = "1.16", optional = true }             # for ONNX support
ndarray = "0.15"         # for tensor operations
tokenizers = "0.14"      # for text tokenization

# Model format conversion dependencies
safetensors = "0.4"      # for SafeTensors format support
# tch = { version = "0.13", optional = true } # PyTorch bindings (optional) - temporarily disabled
hf-hub = "0.3"           # for Hugging Face model downloads
memmap2 = "0.9"          # for memory-mapped file I/O
byteorder = "1.5"        # for binary data handling
half = "2.3"             # for half-precision floating point
num-traits = "0.2"       # for numeric trait abstractions

# System info and platform detection
sysinfo = "0.29"
dirs = "5.0"

# Hashing for model verification and response caching
sha2 = "0.10"
blake3 = "1.5"
xxhash-rust = { version = "0.8", features = ["xxh3"] }
hex = "0.4"

# Path utilities

# Progress bars and indicators
indicatif = "0.17"

# HTTP client and server
reqwest = { version = "0.11", features = ["json", "stream"], optional = true }
axum = { version = "0.7", features = ["ws"] }
tower = "0.4"
tower-http = { version = "0.5", features = ["cors", "trace"] }
hyper = "1.0"

# Compression
flate2 = "1.0"
tar = "0.4"

# Async traits
async-trait = "0.1"

# Box futures
futures-util = "0.3"

# Date and time
chrono = { version = "0.4", features = ["serde"] }
cron = "0.12"  # Cron expression parsing

# CSV processing for batch operations
csv = "1.3"

# ZIP file handling for audit exports
zip = "0.6"

# Random number generation for resilience patterns
rand = "0.8"

# Human-readable time formatting
humantime = "2.1"

# UUID generation for OpenAI API compatibility
uuid = { version = "1.6", features = ["v4", "serde"] }

# Async streaming for OpenAI API
async-stream = "0.3"

# CPU detection
num_cpus = "1.16"

# Async stream utilities for distributed inference
tokio-stream = { version = "0.1", features = ["net"] }

# YAML serialization for cache config export
serde_yaml = "0.9"

# WebSocket support for real-time streaming
# Updated to fix RUSTSEC-2023-0065 (tungstenite DoS vulnerability, CVSSv3 7.5)
tokio-tungstenite = "0.24"

# Security and authentication
base64 = "0.21"
regex = "1.10"
aes-gcm = "0.10"
ring = "0.17"
jsonwebtoken = "9.2"
argon2 = "0.5"

# Email support for alerting
lettre = { version = "0.11", features = ["tokio1", "smtp-transport", "tokio1-native-tls"] }
native-tls = "0.2"

# Serialization and compression for disk cache persistence
bincode = "1.3"
zstd = "0.13"

# Temporary file handling
tempfile = "3.8"

# Desktop support with Tauri v2
# Note: Tauri v1 has been removed. Desktop app is in dashboard/src-tauri/
tauri = { version = "2.8", features = ["macos-private-api", "tray-icon", "image-ico", "image-png"], optional = true }
tauri-plugin-dialog = { version = "2.0", optional = true }
tauri-plugin-fs = { version = "2.0", optional = true }
tauri-plugin-shell = { version = "2.0", optional = true }
tauri-plugin-notification = { version = "2.0", optional = true }
tauri-plugin-os = { version = "2.0", optional = true }
urlencoding = { version = "2.1", optional = true }
rusqlite = { version = "0.31", features = ["bundled", "chrono", "serde_json"], optional = true }
r2d2 = { version = "0.8", optional = true }
r2d2_sqlite = { version = "0.24", optional = true }

[dev-dependencies]
tempfile = "3.8"
assert_cmd = "2.0"
predicates = "3.0"
criterion = { version = "0.5", features = ["html_reports"] }

[build-dependencies]
tauri-build = { git = "https://github.com/tauri-apps/tauri", tag = "tauri-v2.8.5", package = "tauri-build" }

[features]
default = ["reqwest"]  # Minimal default - exclude heavy ML backends for fast development builds
gguf = ["llama-cpp-2"]     # Enable GGUF/llama.cpp backend
onnx = ["ort"]             # Enable ONNX Runtime backend
ml-backends = ["gguf", "onnx"]  # Enable all ML backends
download = ["reqwest"]
gpu-metal = []
gpu-vulkan = []
gpu-directml = []
cuda = []      # NVIDIA CUDA support
rocm = []      # AMD ROCm support
pytorch = []  # Enable PyTorch support - temporarily disabled (deps commented out)
desktop = [  # Tauri v2 desktop app with full features
    "tauri",
    "tauri-plugin-dialog",
    "tauri-plugin-fs",
    "tauri-plugin-shell",
    "tauri-plugin-notification",
    "tauri-plugin-os",
    "urlencoding",
    "rusqlite",
    "r2d2",
    "r2d2_sqlite",
    "gguf",  # Include GGUF support for desktop
]

[profile.release]
lto = true
codegen-units = 1
panic = "abort"
strip = true

[profile.dev]
opt-level = 1

[[bench]]
name = "inference_benchmark"
harness = false

[[bench]]
name = "memory_benchmark"
harness = false

[[bench]]
name = "concurrent_benchmark"
harness = false

[[bench]]
name = "cache_benchmark"
harness = false

[[bench]]
name = "profiling_benchmark"
harness = false

# Fast tests - run by default with `cargo test`
[[test]]
name = "basic_functionality"
path = "tests/basic_functionality.rs"

[[test]]
name = "component_unit_tests"
path = "tests/component_unit_tests.rs"

# Slow integration tests - opt-in only via `cargo test --test <name>` or `./verify.sh`
[[test]]
name = "integration_tests"
path = "tests/integration_tests.rs"
test = false  # Skip in default `cargo test`

[[test]]
name = "feature_integration_tests"
path = "tests/feature_integration_tests.rs"
test = false

[[test]]
name = "end_to_end_tests"
path = "tests/end_to_end_tests.rs"
test = false

[[test]]
name = "audit_system_integration_tests"
path = "tests/audit_system_integration_tests.rs"
test = false

[[test]]
name = "backend_integration_tests"
path = "tests/backend_integration_tests.rs"
test = false

[[test]]
name = "batch_processing_integration_tests"
path = "tests/batch_processing_integration_tests.rs"
test = false

[[test]]
name = "batch_queue_integration_tests"
path = "tests/batch_queue_integration_tests.rs"
test = false

[[test]]
name = "cache_persistence_integration_tests"
path = "tests/cache_persistence_integration_tests.rs"
test = false

[[test]]
name = "conversion_integration_tests"
path = "tests/conversion_integration_tests.rs"
test = false

[[test]]
name = "cross_component_integration_tests"
path = "tests/cross_component_integration_tests.rs"
test = false

[[test]]
name = "dashboard_api_tests"
path = "tests/dashboard_api_tests.rs"
test = false

[[test]]
name = "dashboard_api_workflow_tests"
path = "tests/dashboard_api_workflow_tests.rs"
test = false

[[test]]
name = "performance_stress_tests"
path = "tests/performance_stress_tests.rs"
test = false

[[test]]
name = "platform_integration"
path = "tests/platform_integration.rs"
test = false

[[test]]
name = "error_size_analysis"
path = "tests/error_size_analysis.rs"
test = false

[[test]]
name = "metrics_thread_safety"
path = "tests/metrics_thread_safety.rs"
test = false

[package.metadata.docs.rs]
all-features = true
rustdoc-args = ["--cfg", "docsrs"]
